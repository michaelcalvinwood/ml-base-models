{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YF5a-cq3Goxf",
        "oo6ez_kwHHiP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Arrays\n"
      ],
      "metadata": {
        "id": "tj5caGvc8H48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://array-3d-viz.vercel.app/\n"
      ],
      "metadata": {
        "id": "TriJ5nGY8LR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GANS\n",
        "\n",
        "https://thispersondoesnotexist.com\n",
        "\n",
        "http://whichfaceisreal.com\n"
      ],
      "metadata": {
        "id": "m19T5iGxlYzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building AI Models from Scratch â€” No Libraries"
      ],
      "metadata": {
        "id": "J6KpEaJEHJ5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://neuralnetworksanddeeplearning.com/chap1.html"
      ],
      "metadata": {
        "id": "as8CvD51HQu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learn Neural Networks Visually\n",
        "\n"
      ],
      "metadata": {
        "id": "YF5a-cq3Goxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TensorFlow Playground (Regression & Classification): https://playground.tensorflow.org/\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Using Playground:https://cloud.google.com/blog/products/ai-machine-learning/understanding-neural-networks-with-tensorflow-playground\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://www.druva.com/blog/understanding-neural-networks-through-visualization\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://www.youtube.com/watch?v=rti0Ozfeqn8\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://www.youtube.com/watch?v=ZNrmS6q_Zp4\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://deeperplayground.org/#activation=tanh&regularization=L2&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.54787&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&animationSpeed=100&layerwiseGradientNormalization=0&learningRateAutotuning=-1&preventLossIncreases=false&dropout=0&momentum=0\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://playground.geosci.ai/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0.01&noise=0&networkShape=4&seed=0.01820&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
        "\n",
        "CNN Visual Playground and Explanation: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://convnetplayground.fastforwardlabs.com/#/\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CNN Keras Tutorial: https://www.kaggle.com/code/prashant111/comprehensive-guide-to-cnn-with-keras\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Popular CNN Models: https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Great explanation of Top 5 CNN Models:https://towardsdatascience.com/5-most-well-known-cnn-architectures-visualized-af76f1f0065e"
      ],
      "metadata": {
        "id": "f0EQlMJkrb2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication\n"
      ],
      "metadata": {
        "id": "oo6ez_kwHHiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Visualization: http://matrixmultiplication.xyz/\n",
        "\n",
        "Explanation: https://www.mathsisfun.com/algebra/matrix-multiplying.html"
      ],
      "metadata": {
        "id": "tjcTKl0Xrkvi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pM4OSNkuIIPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cheat Sheets"
      ],
      "metadata": {
        "id": "Z857921Crngx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Functions: https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\n",
        "\n"
      ],
      "metadata": {
        "id": "3DigbjdqrqZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Neural Networks"
      ],
      "metadata": {
        "id": "HQkEMUdjueFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIT Introduction to Neural Networks: https://www.youtube.com/watch?v=iaSUYvmCekI&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=4"
      ],
      "metadata": {
        "id": "yTsdDlIfuipT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DjkmfhCulT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Trained Models!!!"
      ],
      "metadata": {
        "id": "ZrhKMwUi8zL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow Hub"
      ],
      "metadata": {
        "id": "Fqqt6TbF81hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now we're going to do a similar process, except the majority of our model's layers are going to come from [TensorFlow Hub](https://tfhub.dev/).\n",
        "\n",
        "In fact, we're going to use two models from TensorFlow Hub:\n",
        "1. [ResNetV2](https://arxiv.org/abs/1603.05027) -  a state of the art computer vision model architecture from 2016.\n",
        "2. [EfficientNet](https://arxiv.org/abs/1905.11946) - a state of the art computer vision architecture from 2019.\n",
        "\n",
        "**State of the art means that at some point, both of these models have achieved the lowest error rate on [ImageNet (ILSVRC-2012-CLS)](http://www.image-net.org/), the gold standard of computer vision benchmarks.**\n",
        "\n",
        "How do you find these models on TensorFlow Hub?\n",
        "\n",
        "1. Go to [tfhub.dev](https://tfhub.dev/).\n",
        "2. Choose your problem domain, e.g. \"Image\" (we're using food images).\n",
        "3. Select your TF version, which in our case is TF2.\n",
        "4. Remove all \"Problem domanin\" filters except for the problem you're working on.\n",
        "  * **Note:** \"Image feature vector\" can be used alongside almost any problem, we'll get to this soon.\n",
        "5. The models listed are all models which could potentially be used for your problem.\n",
        "\n",
        "> ðŸ¤” **Question:** *I see many options for image classification models, how do I know which is best?*\n",
        "\n",
        "You can see a list of state of the art models on [paperswithcode.com](https://www.paperswithcode.com), a resource for collecting the latest in deep learning paper results which have code implementations for the findings they report.\n",
        "\n",
        "Since we're working with images, our target are the [models which perform best on ImageNet](https://paperswithcode.com/sota/image-classification-on-imagenet).\n",
        "\n",
        "You'll probably find not all of the model architectures listed on paperswithcode appear on TensorFlow Hub. And this is okay, we can still use what's available.\n",
        "\n",
        "To find our models, let's narrow down our search using the Architecture tab.\n",
        "\n",
        "6. Select the Architecture tab on TensorFlow Hub and you'll see a dropdown menu of architecture names appear.\n",
        "  * The rule of thumb here is generally, names with larger numbers means better performing models. For example, EfficientNetB4 performs better than EfficientNetB0.\n",
        "    * However, the tradeoff with larger numbers can mean they take longer to compute.\n",
        "7. Select EfficientNetB0 and you should see [something like the following](https://tfhub.dev/s?module-type=image-classification,image-feature-vector&network-architecture=efficientnet-b0&tf-version=tf2):\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-tensorflow-hub-efficientnetb0.png)\n",
        "8. Clicking the one titled \"[efficientnet/b0/feature-vector](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1)\" brings us to a page with a button that says \"Copy URL\". That URL is what we can use to harness the power of EfficientNetB0.\n",
        "  * Copying the URL should give you something like this: https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n",
        "\n",
        "> ðŸ¤” **Question:** *I thought we were doing image classification, why do we choose feature vector and not classification?*\n",
        "\n",
        "Great observation. This is where the differnet types of transfer learning come into play, as is, feature extraction and fine-tuning.\n",
        "\n",
        "1. **\"As is\" transfer learning** is when you take a pretrained model as it is and apply it to your task without any changes.\n",
        "\n",
        "  * For example, many computer vision models are pretrained on the ImageNet dataset which contains 1000 different classes of images. This means passing a single image to this model will produce 1000 different prediction probability values (1 for each class).\n",
        "\n",
        "    * This is helpful if you have 1000 classes of image you'd like to classify and they're all the same as the ImageNet classes, however, it's not helpful if you want to classify only a small subset of classes (such as 10 different kinds of food). Model's with `\"/classification\"` in their name on TensorFlow Hub provide this kind of functionality.\n",
        "\n",
        "2. **Feature extraction transfer learning** is when you take the underlying patterns (also called weights) a pretrained model has learned and adjust its outputs to be more suited to your problem.\n",
        "\n",
        "  * For example, say the pretrained model you were using had 236 different layers (EfficientNetB0 has 236 layers), but the top layer outputs 1000 classes because it was pretrained on ImageNet. To adjust this to your own problem, you might remove the original activation layer and replace it with your own but with the right number of output classes. The important part here is that **only the top few layers become trainable, the rest remain frozen**.\n",
        "\n",
        "    * This way all the underlying patterns remain in the rest of the layers and you can utilise them for your own problem. This kind of transfer learning is very helpful when your data is similar to the data a model has been pretrained on.\n",
        "\n",
        "3. **Fine-tuning transfer learning** is when you take the underlying patterns (also called weights) of a pretrained model and adjust (fine-tune) them to your own problem.\n",
        "\n",
        "    * This usually means training **some, many or all** of the layers in the pretrained model. This is useful when you've got a large dataset (e.g. 100+ images per class) where your data is slightly different to the data the original model was trained on.\n",
        "\n",
        "A common workflow is to \"freeze\" all of the learned patterns in the bottom layers of a pretrained model so they're untrainable. And then train the top 2-3 layers of so the pretrained model can adjust its outputs to your custom data (**feature extraction**).\n",
        "\n",
        "After you've trained the top 2-3 layers, you can then gradually \"unfreeze\" more and more layers and run the training process on your own data to further **fine-tune** the pretrained model.\n",
        "\n",
        "> ðŸ¤” **Question:** *Why train only the top 2-3 layers in feature extraction?*\n",
        "\n",
        "The lower a layer is in a computer vision model as in, the closer it is to the input layer, the larger the features it learn. For example, a bottom layer in a computer vision model to identify images of cats or dogs might learn the outline of legs, where as, layers closer to the output might learn the shape of teeth. Often, you'll want the larger features (learned patterns are also called features) to remain, since these are similar for both animals, where as, the differences remain in the more fine-grained features.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-different-kinds-of-transfer-learning.png)\n",
        "*The different kinds of transfer learning. An original model, a feature extraction model (only top 2-3 layers change) and a fine-tuning model (many or all of original model get changed).*\n",
        "\n",
        "Okay, enough talk, let's see this in action. Once we do, we'll explain what's happening.\n",
        "\n",
        "First we'll import TensorFlow and TensorFlow Hub."
      ],
      "metadata": {
        "id": "0egIzBzf890n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5rwBJRj9Ok6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights & Biases: https://wandb.ai/site\n"
      ],
      "metadata": {
        "id": "3mrwdxX0sSYx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2aOQgQNsdWH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}